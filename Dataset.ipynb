{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4416b85c-4235-4efe-9121-d70786e2c16e",
   "metadata": {},
   "source": [
    "## Creating the Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f81216f4-ca18-4b4d-8807-ab26bd01c763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import Pk_library as PKL\n",
    "import density_field_library as DFL\n",
    "import smoothing_library as SL\n",
    "\n",
    "class data_gen(Dataset):\n",
    "\n",
    "    def __init__(self, n, mode, dens_case, dens_cut_str, kmax_cut_str, A_true):\n",
    "        super().__init__()\n",
    "\n",
    "        data = np.zeros((n,64,64))\n",
    "        A = np.zeros(n)\n",
    "\n",
    "        seed_arr = np.zeros(n)\n",
    "        for i in range(n):\n",
    "            seed_arr[i] = i\n",
    "\n",
    "        for i in range(n):\n",
    "\n",
    "            grid              = 64                     \n",
    "            BoxSize           = 1000           \n",
    "            seed              = int(seed_arr[i])      \n",
    "            Rayleigh_sampling = 1           \n",
    "            threads           = 1                                          \n",
    "            verbose           = False\n",
    "            MAS               = 'None'                          \n",
    "                \n",
    "            kf = 7e-03\n",
    "            kmax = 0.9\n",
    "            k = np.arange(3*kf, kmax, kf)\n",
    "            k = k.astype(np.float32)\n",
    "\n",
    "            Pk = []\n",
    "            if A_true == None:\n",
    "                np.random.seed(seed)\n",
    "                A_1 = np.random.uniform(0.8,1.2)\n",
    "            else:\n",
    "                A_1 = A_true\n",
    "\n",
    "            for j in k:\n",
    "                Pk_1 = A_1/(np.sqrt(j))\n",
    "                Pk.append(Pk_1)\n",
    "\n",
    "            Pk = np.array(Pk)\n",
    "            Pk = Pk.astype(np.float32)\n",
    "\n",
    "            data_1 = DFL.gaussian_field_2D(grid, k, Pk, Rayleigh_sampling, seed,\n",
    "                BoxSize, threads, verbose)\n",
    "\n",
    "            if kmax_cut_str != None:\n",
    "                filter            = 'Top-Hat-k'\n",
    "                R                 = 0.0\n",
    "                k_min             = 0  \n",
    "                k_max             = float(kmax_cut_str)\n",
    "                W_k = SL.FT_filter_2D(BoxSize, R, grid, filter, threads, k_min, k_max)\n",
    "                field_smoothed = SL.field_smoothing_2D(data_1, W_k, threads)\n",
    "                data[i,:,:] = field_smoothed\n",
    "            else:\n",
    "                data[i,:,:] = data_1\n",
    "\n",
    "            #normalising A wrt maximum and minimum\n",
    "            A_2 = (A_1 - 0.8)/(1.2-0.8)\n",
    "            A[i] = A_2\n",
    "\n",
    "        if dens_case != 'original':\n",
    "            dens_cut = float(dens_cut_str)\n",
    "            if dens_case == 'min':\n",
    "                indexes = np.where(data<dens_cut)\n",
    "                data[indexes] = dens_cut\n",
    "            else:\n",
    "                indexes = np.where(data>dens_cut)\n",
    "                data[indexes] = dens_cut  \n",
    "\n",
    "                \n",
    "        if   mode=='train':  offset, size_maps = int(0.00*n), int(0.70*n)\n",
    "        elif mode=='valid':  offset, size_maps = int(0.70*n), int(0.15*n)\n",
    "        elif mode=='test':   offset, size_maps = int(0.85*n), int(0.15*n)\n",
    "        elif mode=='all':    offset, size_maps = int(0.00*n), int(1.00*n)\n",
    "        else:                raise Exception('Wrong name!')\n",
    "\n",
    "        data = data[offset:offset+size_maps,:]\n",
    "        A = A[offset:offset+size_maps]\n",
    "        \n",
    "        #mean and standard deviation of the training set of analysis_mode = 'original'\n",
    "        #(no augmentations) maps\n",
    "        #will change depending on the type of data being trained on\n",
    "        mean, std = 4.864242144507703e-13, 0.10662432912867778\n",
    "        data = (data - mean)/std\n",
    "        data = np.expand_dims(data, axis=1)\n",
    "        data_t = torch.from_numpy(data)\n",
    "        self.data_t = data_t\n",
    "\n",
    "        A_t = torch.from_numpy(A)\n",
    "        A_t = A_t.view(size_maps,1)\n",
    "        self.A = A_t\n",
    "\n",
    "        self.size = self.data_t.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_t[idx].to(torch.float32), self.A[idx].to(torch.float32)\n",
    "    \n",
    "    def full_data(self):\n",
    "        return(self.data_t)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63867be-1813-4e33-b58a-a4c03a736521",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_ml_2.0",
   "language": "python",
   "name": "py_ml_2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
